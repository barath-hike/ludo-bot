{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 21:01:28.548154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from Agents.DQNAgent import DQNAgent\n",
    "from Boards.Speed_leedo_2p import FullBoard\n",
    "import sys\n",
    "import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from tornado import concurrent\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "env = FullBoard()\n",
    "\n",
    "# 0 - load data, 1 - read/process, 2 - do nothing\n",
    "main_data = 2\n",
    "game_history_data = 2\n",
    "state_process = 0\n",
    "data_q_val = 1\n",
    "\n",
    "post = 'sep_6_to_sep_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_data != 2:\n",
    "    if main_data:\n",
    "        query=\"\"\"\n",
    "            select *\n",
    "            from `analytics-156605.barath.ludo_details_1`\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_gbq(query, use_bqstorage_api=True, progress_bar_type='tqdm_notebook')\n",
    "\n",
    "        df.to_feather('../data/ludo_2p_data_' + post)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        df = pd.read_feather('../data/ludo_2p_data_' + post)\n",
    "\n",
    "    df = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if game_history_data != 2:\n",
    "#     if game_history_data:\n",
    "\n",
    "#         query=\"\"\"\n",
    "#                 select *\n",
    "#                 from `analytics-156605.barath.game_history`\n",
    "#             \"\"\"\n",
    "\n",
    "#         game_history = pd.read_gbq(query, use_bqstorage_api=True, progress_bar_type='tqdm_notebook')\n",
    "\n",
    "#         game_history.to_feather('../data/game_history_1_to_15.feather')\n",
    "        \n",
    "#     else:\n",
    "\n",
    "#         game_history = pd.read_feather('../data/game_history_1_to_15.feather')\n",
    "\n",
    "#     game_history = game_history.to_dict('records')\n",
    "#     game_history = {item['user_id']:item['f0_'] for item in game_history if item is not None}\n",
    "#     # game_history = game_history.groupby('user_id').apply(lambda x: dict(zip(x.game_ref_id, x.last_5))).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2547029/2547029 [15:08<00:00, 2803.60it/s]\n"
     ]
    }
   ],
   "source": [
    "if state_process != 2:\n",
    "    if state_process:\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "        def func(group):\n",
    "\n",
    "            def extract_pos(x):\n",
    "                return np.array([json.loads(i) for i in x])\n",
    "\n",
    "            def extract_home(x):\n",
    "                temp = np.array([json.loads(i) for i in x])\n",
    "                temp[temp=='HOME'] = 1\n",
    "                temp[temp!='HOME'] = 0\n",
    "                temp = temp.astype('float32')\n",
    "                temp = np.sum(temp, -1)\n",
    "                return np.expand_dims(temp, -1)\n",
    "\n",
    "            def my_argmax(a):\n",
    "                rows = np.where(a == a.max(axis=1)[:, None])[0]\n",
    "                rows_multiple_max = rows[:-1][rows[:-1] == rows[1:]]\n",
    "                my_argmax = a.argmax(axis=1)\n",
    "                my_argmax[rows_multiple_max] = -1\n",
    "                return my_argmax\n",
    "\n",
    "            try:\n",
    "\n",
    "                if len(group['pawns_position_1']) > 25 and len(group['pawns_position_2']) > 25:\n",
    "                    \n",
    "                    pawn_position_1 = extract_pos(group['pawns_position_1'])\n",
    "                    pawn_position_2 = extract_pos(group['pawns_position_2'])\n",
    "                    home_1 = extract_home(group['home_1'])\n",
    "                    home_2 = extract_home(group['home_2'])\n",
    "\n",
    "                    if len(pawn_position_1) != len(pawn_position_2):\n",
    "                        length = np.min([len(pawn_position_1), len(pawn_position_2)])\n",
    "                        pawn_position_1 = pawn_position_1[:length]\n",
    "                        pawn_position_2 = pawn_position_2[:length]\n",
    "                        home_1 = home_1[:length]\n",
    "                        home_2 = home_2[:length]\n",
    "\n",
    "                    first_user = group['from_user'][0]\n",
    "                    second_user = group['opponent'][0]\n",
    "                    \n",
    "                    from_user = np.array(group['from_user'])\n",
    "                    dice = np.array(group['dice_score'])\n",
    "\n",
    "                    user_ids = (from_user == second_user).astype('float32')\n",
    "                    user_ids = user_ids[1:]\n",
    "                    dice = dice[1:]\n",
    "\n",
    "                    pos = np.concatenate((pawn_position_1, pawn_position_2), axis=-1)\n",
    "                    home = np.concatenate((home_1, home_2), -1)\n",
    "                    score = [np.sum(json.loads(group['score_1'][-1])), np.sum(json.loads(group['score_2'][-1]))]\n",
    "                    mu_0 = group['mu'][0]\n",
    "                    sigma_0 = group['sigma'][0]\n",
    "                    idx = np.where(group['from_user'] == second_user)[0][0]\n",
    "                    mu_1 = group['mu'][idx]\n",
    "                    sigma_1 = group['sigma'][idx]\n",
    "\n",
    "                    score = np.array(score)\n",
    "\n",
    "                    action_1 = my_argmax((pawn_position_1[1:] - pawn_position_1[:-1]))\n",
    "                    action_2 = my_argmax((pawn_position_2[1:] - pawn_position_2[:-1]))\n",
    "                    action = np.copy(action_1)\n",
    "                    action[action==-1] = action_2[action==-1]\n",
    "\n",
    "                    states = np.concatenate((np.expand_dims(dice, -1).astype('float32'), pos[:-1,:], home[:-1,:]), -1)\n",
    "\n",
    "                    return {'division': group['division'], 'user_id_0': first_user, 'user_id_1': second_user,\n",
    "                                'user_ids': user_ids, 'score': score, \n",
    "                                'states': states, 'action': action,\n",
    "                                'mu_0': mu_0, 'sigma_0': sigma_0,\n",
    "                                'mu_1': mu_1, 'sigma_1': sigma_1}\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        p = Pool(16)\n",
    "\n",
    "        results = p.map(func, tqdm.tqdm(df))\n",
    "\n",
    "        results = [i for i in results if i is not None]\n",
    "        \n",
    "        with open('../data/state_data_' + post + '.pkl', 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        with open('../data/state_data_' + post + '.pkl', 'rb') as f:\n",
    "            results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 06:36:47.108462: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-09-21 06:36:47.109503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-09-21 06:36:47.144890: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-09-21 06:36:47.144940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ds-rnd-t4-32c-02\n",
      "2022-09-21 06:36:47.144948: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ds-rnd-t4-32c-02\n",
      "2022-09-21 06:36:47.145071: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1\n",
      "2022-09-21 06:36:47.145099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1\n",
      "2022-09-21 06:36:47.145105: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1\n",
      "2022-09-21 06:36:47.145465: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-21 06:36:47.148192: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "  0%|          | 8746/2347806 [00:00<02:37, 14890.43it/s]2022-09-21 06:36:48.552203: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "  0%|          | 10707/2347806 [00:01<04:07, 9445.46it/s]2022-09-21 06:36:48.552788: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
      "100%|██████████| 2347806/2347806 [01:25<00:00, 27342.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/nfs_storage/fs-mnt6/barathmohanU/ludo_bot/LudoRL/q_value_model_data_cop1.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.28.0.12/nfs_storage/fs-mnt6/barathmohanU/ludo_bot/LudoRL/q_value_model_data_cop1.ipynb#ch0000004vscode-remote?line=29'>30</a>\u001b[0m     \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(results):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.28.0.12/nfs_storage/fs-mnt6/barathmohanU/ludo_bot/LudoRL/q_value_model_data_cop1.ipynb#ch0000004vscode-remote?line=30'>31</a>\u001b[0m         future \u001b[39m=\u001b[39m executor\u001b[39m.\u001b[39msubmit(func1, d)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.28.0.12/nfs_storage/fs-mnt6/barathmohanU/ludo_bot/LudoRL/q_value_model_data_cop1.ipynb#ch0000004vscode-remote?line=31'>32</a>\u001b[0m         futures\u001b[39m.\u001b[39mappend(future)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.28.0.12/nfs_storage/fs-mnt6/barathmohanU/ludo_bot/LudoRL/q_value_model_data_cop1.ipynb#ch0000004vscode-remote?line=33'>34</a>\u001b[0m results1 \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.28.0.12/nfs_storage/fs-mnt6/barathmohanU/ludo_bot/LudoRL/q_value_model_data_cop1.ipynb#ch0000004vscode-remote?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m future \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(futures):\n",
      "File \u001b[0;32m/nfs_storage/fs-mnt6/barathmohanU/miniconda3/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    638\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/nfs_storage/fs-mnt6/barathmohanU/miniconda3/lib/python3.9/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m/nfs_storage/fs-mnt6/barathmohanU/miniconda3/lib/python3.9/threading.py:1053\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1053\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1055\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/nfs_storage/fs-mnt6/barathmohanU/miniconda3/lib/python3.9/threading.py:1073\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1073\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1074\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1075\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if data_q_val:\n",
    "    \n",
    "    agent0 = DQNAgent(env.state_size(), env.action_size(), env.max_val())\n",
    "    agent0.load('./model_output/DQN_2p_v2/0004/weights_100000.hdf5')\n",
    "\n",
    "    # for dat in tqdm.tqdm(data):\n",
    "        \n",
    "        # group = data[dat]\n",
    "\n",
    "    def func1(group):\n",
    "\n",
    "        if len(np.squeeze(np.array(group['states'])).shape) == 2:\n",
    "\n",
    "            q_vals = np.squeeze(agent0.model.predict(np.reshape(group['states'], [len(group['states']),11,1])/69))\n",
    "            q_temp = np.array([q_vals[i,group['action'][i]] for i in range(len(group['states']))])\n",
    "            q_max = np.max(q_vals, -1)\n",
    "            q_min = np.min(q_vals, -1)\n",
    "            # data[dat].update({'q_user_0': q_temp[group['user_ids']==0],\n",
    "            #                   'q_user_1': q_temp[group['user_ids']==1],\n",
    "            #                   'q_max_user_0': q_max[group['user_ids']==0],\n",
    "            #                   'q_max_user_1': q_max[group['user_ids']==1]})\n",
    "            \n",
    "            return {'q_user_0': q_temp[group['user_ids']==0],\n",
    "                    'q_user_1': q_temp[group['user_ids']==1],\n",
    "                    'q_max_user_0': q_max[group['user_ids']==0],\n",
    "                    'q_max_user_1': q_max[group['user_ids']==1],\n",
    "                    'q_min_user_0': q_min[group['user_ids']==0],\n",
    "                    'q_min_user_1': q_min[group['user_ids']==1]}\n",
    "\n",
    "    # futures = []\n",
    "    # with concurrent.futures.ThreadPoolExecutor(max_workers=24) as executor:\n",
    "    #     for d in tqdm.tqdm(results):\n",
    "    #         future = executor.submit(func1, d)\n",
    "    #         futures.append(future)\n",
    "\n",
    "    results1 = []\n",
    "    for i, d in enumerate(tqdm.tqdm(results)):\n",
    "        results1.append(func1(d))\n",
    "\n",
    "        if i % 100000 == 0:\n",
    "            with open('../data/q_val_data_' + post + '.pkl', 'wb') as f:\n",
    "                pickle.dump([results, results1], f)\n",
    "\n",
    "    # for future in tqdm.tqdm(futures):\n",
    "    #     results1.append(future.result())\n",
    "\n",
    "    with open('../data/q_val_data_' + post + '.pkl', 'wb') as f:\n",
    "        pickle.dump([results, results1], f)\n",
    "\n",
    "else:\n",
    "\n",
    "    with open('../data/q_val_data_' + post + '.pkl', 'rb') as f:\n",
    "        results, results1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(results)):\n",
    "#     results[i].update(results1[i])\n",
    "\n",
    "# data = {item['division']:item for item in results if item is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_data = {}\n",
    "\n",
    "# for dat in data:\n",
    "#     if 'q_user_0' in data[dat]:\n",
    "#         q_data[dat] = {}\n",
    "#         q_data[dat][data[dat]['user_id_0']] = {'q': data[dat]['q_user_0'], 'q_max': data[dat]['q_max_user_0'], \n",
    "#                                             'win': int(data[dat]['score'][0] > data[dat]['score'][1]),\n",
    "#                                             'mu': data[dat]['mu_0'], 'sigma': data[dat]['sigma_0']}\n",
    "#         q_data[dat][data[dat]['user_id_1']] = {'q': data[dat]['q_user_1'], 'q_max': data[dat]['q_max_user_1'], \n",
    "#                                             'win': int(data[dat]['score'][1] > data[dat]['score'][0]),\n",
    "#                                             'mu': data[dat]['mu_1'], 'sigma': data[dat]['sigma_1']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = []\n",
    "# y = []\n",
    "\n",
    "# for dat in tqdm.tqdm(q_data):\n",
    "#     user_id_0 = list(q_data[dat].keys())[0]\n",
    "#     user_id_1 = list(q_data[dat].keys())[1]\n",
    "#     if user_id_0 in game_history and user_id_1 in game_history and dat in game_history[user_id_0] and dat in game_history[user_id_1]:\n",
    "#         pos_1 = np.where(game_history[user_id_0] == dat)[0][0]\n",
    "#         pos_2 = np.where(game_history[user_id_1] == dat)[0][0]\n",
    "#         if pos_1 >= 5 and pos_2 >= 5:\n",
    "#             idx_1 = []\n",
    "#             for i in range (0, pos_1):\n",
    "#                 if game_history[user_id_0][i] in q_data:\n",
    "#                     idx_1.append(True)\n",
    "#                 else:\n",
    "#                     idx_1.append(False)\n",
    "#             idx_2 = []\n",
    "#             for i in range (0, pos_2):\n",
    "#                 if game_history[user_id_1][i] in q_data:\n",
    "#                     idx_2.append(True)\n",
    "#                 else:\n",
    "#                     idx_2.append(False)\n",
    "#             if np.sum(idx_1) >= 5 and np.sum(idx_2) >= 5:\n",
    "#                 q_mean_0 = []\n",
    "#                 q_max_mean_0 = []\n",
    "#                 q_mean_1 = []\n",
    "#                 q_max_mean_1 = []\n",
    "\n",
    "#                 games = game_history[user_id_0][:pos_1][idx_1]\n",
    "#                 games = games[-5:]\n",
    "#                 for i in range(len(games)):\n",
    "#                     q_mean_0.append(np.mean(q_data[games[i]][user_id_0]['q']))\n",
    "#                     q_max_mean_0.append(np.mean(q_data[games[i]][user_id_0]['q_max']))\n",
    "\n",
    "#                 games = game_history[user_id_1][:pos_2][idx_2]\n",
    "#                 games = games[-5:]\n",
    "#                 for i in range(len(games)):\n",
    "#                     q_mean_1.append(np.mean(q_data[games[i]][user_id_1]['q']))\n",
    "#                     q_max_mean_1.append(np.mean(q_data[games[i]][user_id_1]['q_max']))\n",
    "\n",
    "#                 mu_0 = q_data[dat][user_id_0]['mu']\n",
    "#                 mu_1 = q_data[dat][user_id_1]['mu']\n",
    "\n",
    "#                 sigma_0 = q_data[dat][user_id_0]['sigma']\n",
    "#                 sigma_1 = q_data[dat][user_id_1]['sigma']\n",
    "\n",
    "#                 temp_feat = q_mean_0 + q_max_mean_0 + [mu_0, sigma_0] + q_mean_1 + q_max_mean_1 + [mu_1, sigma_1]\n",
    "#                 temp_y = q_data[dat][user_id_0]['win']\n",
    "\n",
    "#                 feats.append(temp_feat)\n",
    "#                 y.append(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/ludo_qval_features_1_to_15.pkl', 'wb') as f:\n",
    "#     pickle.dump([np.array(feats), np.array(y)], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f44b79a3083351f69b3e1c3080f8b68c85400f1e3f9274646c7d9776fff2bccb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
