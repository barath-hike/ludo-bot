{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# from Runners.Ludo_DQN import run_game\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# from Runners.Ludo_AC import run_game\n",
    "# from Runners.Ludo_Reinforce import run_game\n",
    "from Runners_vs_intbot.Ludo_AC_2p_v6_batch import run_game\n",
    "# from Runners.Ludo_AC_Multi import run_game\n",
    "# from Runners.Run_Small import run_game\n",
    "\n",
    "\n",
    "def main():\n",
    "    episodes = 200_001\n",
    "    run_no = 1\n",
    "    run_id = s1 = f'{run_no:04d}'\n",
    "\n",
    "    returns = run_game(episodes, run_id)\n",
    "\n",
    "    string = print_full(returns, run_id)\n",
    "    # string = print_small(returns, run_id)\n",
    "\n",
    "    print(\"RUN %s complete\" % run_id)\n",
    "    print(string)\n",
    "\n",
    "\n",
    "def print_full(returns, run_id):\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    string = '%s_%s.txt' % (date_time, run_id)\n",
    "    file_path = \"results/\"\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "    f = open(\"%s%s\" % (file_path, string), \"a\")\n",
    "\n",
    "    f.write(','.join(str(e) for e in returns[0]))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(','.join(str(e) for e in returns[1]))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(','.join(str(e) for e in returns[2]))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(','.join(str(e) for e in returns[3]))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(','.join(str(e) for e in returns[4]))\n",
    "    f.write(\"\\n\")\n",
    "    # f.write(','.join(str(e) for e in returns[5]))\n",
    "    # f.write(\"\\n\")\n",
    "    f.flush()\n",
    "    f.close()\n",
    "    return string\n",
    "\n",
    "\n",
    "def print_small(returns, run_id):\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    string = '%s_%s.txt' % (date_time, run_id)\n",
    "    file_path = \"results/small/\"\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "    f = open(\"results/small/%s.txt\" % string, \"a\")\n",
    "\n",
    "    f.write(','.join(str(e) for e in returns[0]))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(','.join(str(e) for e in returns[1]))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(','.join(str(e) for e in returns[2]))\n",
    "    f.write(\"\\n\")\n",
    "    f.flush()\n",
    "    f.close()\n",
    "\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 15:43:26.831847: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-18 15:43:26.831908: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ds-rnd-t4-32c-02\n",
      "2022-10-18 15:43:26.831918: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ds-rnd-t4-32c-02\n",
      "2022-10-18 15:43:26.832015: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1\n",
      "2022-10-18 15:43:26.832060: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1\n",
      "2022-10-18 15:43:26.832067: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1\n",
      "2022-10-18 15:43:26.832518: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "  0%|          | 0/5 [00:00<?, ?e/s]../Intelligent_bot/intelligent_bot.py:140: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.pawn_priority[i] = self.pawn_priority[i] * 0.1 / self.pawn_score[i]\n",
      " 20%|##        | 1/5 [00:08<00:33,  8.27s/e]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|####      | 2/5 [00:16<00:24,  8.23s/e]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|######    | 3/5 [00:24<00:16,  8.10s/e]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|########  | 4/5 [00:32<00:07,  7.94s/e]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 5/5 [00:40<00:00,  8.00s/e]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19650/3782429739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lprun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-f run_game returns = run_game(episodes, run_id)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# string = print_small(returns, run_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19650/1365426654.py\u001b[0m in \u001b[0;36mprint_full\u001b[0;34m(returns, run_id)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 40.4324 s\n",
      "File: ../Runners_vs_intbot/Ludo_AC_2p_v6_batch.py\n",
      "Function: run_game at line 15\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    15                                           def run_game(num_ep, model_output):\n",
      "    16         1        406.0    406.0      0.0      env = FullBoard()\n",
      "    17         1     424890.0 424890.0      1.1      agent0 = Agent(n_actions=env.action_size(), input_dim=env.state_size(), alpha=1e-8, max_val=env.max_val())\n",
      "    18         1         23.0     23.0      0.0      bot0 = Bot()\n",
      "    19                                           \n",
      "    20         1          2.0      2.0      0.0      wins = []\n",
      "    21                                           \n",
      "    22         1          1.0      1.0      0.0      agent0_reward = []\n",
      "    23         1          1.0      1.0      0.0      agent1_reward = []\n",
      "    24         1          1.0      1.0      0.0      episode_length = []\n",
      "    25                                           \n",
      "    26         1          3.0      3.0      0.0      output_dir_a = 'model_output_vs_intbot/A2C_v6_batch/%s/actor/' % model_output\n",
      "    27         1          1.0      1.0      0.0      output_dir_c = 'model_output_vs_intbot/A2C_v6_batch/%s/critic/' % model_output\n",
      "    28                                           \n",
      "    29         1        893.0    893.0      0.0      if not os.path.exists(output_dir_a):\n",
      "    30                                                   os.makedirs(output_dir_a)\n",
      "    31         1        264.0    264.0      0.0      if not os.path.exists(output_dir_c):\n",
      "    32                                                   os.makedirs(output_dir_c)\n",
      "    33                                           \n",
      "    34         6      11313.0   1885.5      0.0      for ep in tqdm(range(0, num_ep), ascii=True, unit=\"e\"):\n",
      "    35         5         11.0      2.2      0.0          step = 0\n",
      "    36         5       1781.0    356.2      0.0          s, _, game_over, player_turn = env.reset()\n",
      "    37         5          9.0      1.8      0.0          episode_reward = [0.0, 0.0, 0.0, 0.0]\n",
      "    38                                           \n",
      "    39         5         63.0     12.6      0.0          param1 = []\n",
      "    40         5          8.0      1.6      0.0          param2 = []\n",
      "    41         5         23.0      4.6      0.0          param3 = []\n",
      "    42         5         32.0      6.4      0.0          param4 = []\n",
      "    43         5          7.0      1.4      0.0          param5 = []\n",
      "    44                                           \n",
      "    45       650        693.0      1.1      0.0          while not game_over:\n",
      "    46                                           \n",
      "    47       645       2231.0      3.5      0.0              player_turn_temp = env.get_player_turn()\n",
      "    48       645      17594.0     27.3      0.0              env.roll_dice()[0]\n",
      "    49       645       1025.0      1.6      0.0              player_turn = env.get_player_turn()\n",
      "    50                                           \n",
      "    51       645        732.0      1.1      0.0              if player_turn == player_turn_temp:\n",
      "    52                                           \n",
      "    53       645     109486.0    169.7      0.3                  action_list = env.get_next_states(player_turn)\n",
      "    54                                           \n",
      "    55       645        855.0      1.3      0.0                  if action_list:\n",
      "    56       633        722.0      1.1      0.0                      if player_turn == 1:\n",
      "    57       291       3683.0     12.7      0.0                          s_t = env.convert_state(player_turn)\n",
      "    58       291    3866353.0  13286.4      9.6                          action = agent0.act(s_t, action_list)\n",
      "    59                                                               else:\n",
      "    60       342        743.0      2.2      0.0                          s_t = env.return_state()\n",
      "    61       342      87709.0    256.5      0.2                          action = bot0.act(state=s_t, p=player_turn)\n",
      "    62                                           \n",
      "    63       633     105436.0    166.6      0.3                      s_, reward, game_over, player_turn_temp = env.make_step(action)\n",
      "    64                                           \n",
      "    65       633        923.0      1.5      0.0                      if player_turn == 1:\n",
      "    66       291       4141.0     14.2      0.0                          s_t_ = env.convert_state(player_turn)\n",
      "    67       291        488.0      1.7      0.0                          param1.append(s_t)\n",
      "    68       291        374.0      1.3      0.0                          param2.append(action)\n",
      "    69       291        433.0      1.5      0.0                          param3.append(reward[player_turn])\n",
      "    70       291        368.0      1.3      0.0                          param4.append(s_t_)\n",
      "    71       291        376.0      1.3      0.0                          param5.append(game_over)\n",
      "    72                                                                   \n",
      "    73       291   35359501.0 121510.3     87.5                          gc.collect()\n",
      "    74                                           \n",
      "    75       633       4787.0      7.6      0.0                      episode_reward[player_turn] += reward[player_turn]\n",
      "    76                                           \n",
      "    77       633        836.0      1.3      0.0                      step += 1\n",
      "    78                                           \n",
      "    79       645        702.0      1.1      0.0              if game_over:\n",
      "    80         5     385279.0  77055.8      1.0                  agent0.learn(np.array(param1), np.array(param2), np.array(param3), np.array(param4), np.array(param5))\n",
      "    81                                           \n",
      "    82         5         58.0     11.6      0.0                  if episode_reward[1] > 0:\n",
      "    83                                                               wins.append(1)\n",
      "    84                                                           else:\n",
      "    85         5          9.0      1.8      0.0                      wins.append(0)\n",
      "    86         5       1068.0    213.6      0.0                  print('Wins: ', np.sum(wins[-100:]))\n",
      "    87                                           \n",
      "    88         5         13.0      2.6      0.0                  agent0_reward.append(episode_reward[0])\n",
      "    89         5          8.0      1.6      0.0                  agent1_reward.append(episode_reward[1])\n",
      "    90         5         11.0      2.2      0.0                  episode_length.append(step / 2)\n",
      "    91                                           \n",
      "    92         5          7.0      1.4      0.0          if ep > 1000:\n",
      "    93                                                       agent0.reduce_alpha()\n",
      "    94                                           \n",
      "    95         5          8.0      1.6      0.0          if ep % 100 == 0:\n",
      "    96                                                       # print(np.average(agent0_reward[-1000:]), np.average(agent1_reward[-1000:]))\n",
      "    97         1          7.0      7.0      0.0              agent0.save_model(output_dir_a + \"weights_\" + '{:04d}'.format(ep) + \".hdf5\", \n",
      "    98         1      36046.0  36046.0      0.1                                output_dir_c + \"weights_\" + '{:04d}'.format(ep) + \".hdf5\")\n",
      "    99                                           \n",
      "   100         1          2.0      2.0      0.0      return [agent0_reward, agent1_reward, episode_length]"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "run_no = 1\n",
    "run_id = s1 = f'{run_no:04d}'\n",
    "\n",
    "%lprun -f run_game returns = run_game(episodes, run_id)\n",
    "\n",
    "string = print_full(returns, run_id)\n",
    "# string = print_small(returns, run_id)\n",
    "\n",
    "print(\"RUN %s complete\" % run_id)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('rl-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2c9548d151a78bce28fe03d6b80e2a870126e154014100318ab730d04413d79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
