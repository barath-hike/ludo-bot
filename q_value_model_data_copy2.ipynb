{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 17:25:12.432217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from Agents.DQNAgent import DQNAgent\n",
    "from Boards.Speed_leedo_2p import FullBoard\n",
    "import sys\n",
    "import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from tornado import concurrent\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "env = FullBoard()\n",
    "\n",
    "# 0 - load data, 1 - read/process, 2 - do nothing\n",
    "main_data = 2\n",
    "game_history_data = 2\n",
    "state_process = 0\n",
    "data_q_val = 1\n",
    "\n",
    "post = 'sep_11_to_sep_15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bade0893c54414d8981c748dceb4f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/462626 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if main_data != 2:\n",
    "    if main_data:\n",
    "        query=\"\"\"\n",
    "            select *\n",
    "            from `analytics-156605.barath.ludo_details_1`\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_gbq(query, use_bqstorage_api=True, progress_bar_type='tqdm_notebook')\n",
    "\n",
    "        df.to_feather('../data/ludo_2p_data_' + post)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        df = pd.read_feather('../data/ludo_2p_data_' + post)\n",
    "\n",
    "    df = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if game_history_data != 2:\n",
    "#     if game_history_data:\n",
    "\n",
    "#         query=\"\"\"\n",
    "#                 select *\n",
    "#                 from `analytics-156605.barath.game_history`\n",
    "#             \"\"\"\n",
    "\n",
    "#         game_history = pd.read_gbq(query, use_bqstorage_api=True, progress_bar_type='tqdm_notebook')\n",
    "\n",
    "#         game_history.to_feather('../data/game_history_1_to_15.feather')\n",
    "        \n",
    "#     else:\n",
    "\n",
    "#         game_history = pd.read_feather('../data/game_history_1_to_15.feather')\n",
    "\n",
    "#     game_history = game_history.to_dict('records')\n",
    "#     game_history = {item['user_id']:item['f0_'] for item in game_history if item is not None}\n",
    "#     # game_history = game_history.groupby('user_id').apply(lambda x: dict(zip(x.game_ref_id, x.last_5))).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if state_process != 2:\n",
    "    if state_process:\n",
    "\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "        def func(group):\n",
    "\n",
    "            def extract_pos(x):\n",
    "                return np.array([json.loads(i) for i in x])\n",
    "\n",
    "            def extract_home(x):\n",
    "                temp = np.array([json.loads(i) for i in x])\n",
    "                temp[temp=='HOME'] = 1\n",
    "                temp[temp!='HOME'] = 0\n",
    "                temp = temp.astype('float32')\n",
    "                temp = np.sum(temp, -1)\n",
    "                return np.expand_dims(temp, -1)\n",
    "\n",
    "            def my_argmax(a):\n",
    "                rows = np.where(a == a.max(axis=1)[:, None])[0]\n",
    "                rows_multiple_max = rows[:-1][rows[:-1] == rows[1:]]\n",
    "                my_argmax = a.argmax(axis=1)\n",
    "                my_argmax[rows_multiple_max] = -1\n",
    "                return my_argmax\n",
    "\n",
    "            try:\n",
    "\n",
    "                if len(group['pawns_position_1']) > 25 and len(group['pawns_position_2']) > 25:\n",
    "                    \n",
    "                    pawn_position_1 = extract_pos(group['pawns_position_1'])\n",
    "                    pawn_position_2 = extract_pos(group['pawns_position_2'])\n",
    "                    home_1 = extract_home(group['home_1'])\n",
    "                    home_2 = extract_home(group['home_2'])\n",
    "\n",
    "                    if len(pawn_position_1) != len(pawn_position_2):\n",
    "                        length = np.min([len(pawn_position_1), len(pawn_position_2)])\n",
    "                        pawn_position_1 = pawn_position_1[:length]\n",
    "                        pawn_position_2 = pawn_position_2[:length]\n",
    "                        home_1 = home_1[:length]\n",
    "                        home_2 = home_2[:length]\n",
    "\n",
    "                    first_user = group['from_user'][0]\n",
    "                    second_user = group['opponent'][0]\n",
    "                    \n",
    "                    from_user = np.array(group['from_user'])\n",
    "                    dice = np.array(group['dice_score'])\n",
    "\n",
    "                    user_ids = (from_user == second_user).astype('float32')\n",
    "                    user_ids = user_ids[1:]\n",
    "                    dice = dice[1:]\n",
    "\n",
    "                    pos = np.concatenate((pawn_position_1, pawn_position_2), axis=-1)\n",
    "                    home = np.concatenate((home_1, home_2), -1)\n",
    "                    score = [np.sum(json.loads(group['score_1'][-1])), np.sum(json.loads(group['score_2'][-1]))]\n",
    "                    mu_0 = group['mu'][0]\n",
    "                    sigma_0 = group['sigma'][0]\n",
    "                    idx = np.where(group['from_user'] == second_user)[0][0]\n",
    "                    mu_1 = group['mu'][idx]\n",
    "                    sigma_1 = group['sigma'][idx]\n",
    "\n",
    "                    score = np.array(score)\n",
    "\n",
    "                    action_1 = my_argmax((pawn_position_1[1:] - pawn_position_1[:-1]))\n",
    "                    action_2 = my_argmax((pawn_position_2[1:] - pawn_position_2[:-1]))\n",
    "                    action = np.copy(action_1)\n",
    "                    action[action==-1] = action_2[action==-1]\n",
    "\n",
    "                    states = np.concatenate((np.expand_dims(dice, -1).astype('float32'), pos[:-1,:], home[:-1,:]), -1)\n",
    "\n",
    "                    return {'division': group['division'], 'user_id_0': first_user, 'user_id_1': second_user,\n",
    "                                'user_ids': user_ids, 'score': score, \n",
    "                                'states': states, 'action': action,\n",
    "                                'mu_0': mu_0, 'sigma_0': sigma_0,\n",
    "                                'mu_1': mu_1, 'sigma_1': sigma_1}\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        p = Pool(16)\n",
    "\n",
    "        results = p.map(func, tqdm.tqdm(df))\n",
    "\n",
    "        results = [i for i in results if i is not None]\n",
    "        \n",
    "        with open('../data/state_data_' + post + '.pkl', 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        with open('../data/state_data_' + post + '.pkl', 'rb') as f:\n",
    "            results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_q_val:\n",
    "    \n",
    "    agent0 = DQNAgent(env.state_size(), env.action_size(), env.max_val())\n",
    "    agent0.load('./model_output/DQN_2p_v2/0004/weights_100000.hdf5')\n",
    "\n",
    "    # for dat in tqdm.tqdm(data):\n",
    "        \n",
    "        # group = data[dat]\n",
    "\n",
    "    def func1(group):\n",
    "\n",
    "        if len(np.squeeze(np.array(group['states'])).shape) == 2:\n",
    "\n",
    "            q_vals = np.squeeze(agent0.model.predict(np.reshape(group['states'], [len(group['states']),11,1])/69))\n",
    "            q_temp = np.array([q_vals[i,group['action'][i]] for i in range(len(group['states']))])\n",
    "            q_max = np.max(q_vals, -1)\n",
    "            q_min = np.min(q_vals, -1)\n",
    "            # data[dat].update({'q_user_0': q_temp[group['user_ids']==0],\n",
    "            #                   'q_user_1': q_temp[group['user_ids']==1],\n",
    "            #                   'q_max_user_0': q_max[group['user_ids']==0],\n",
    "            #                   'q_max_user_1': q_max[group['user_ids']==1]})\n",
    "            \n",
    "            return {'q_user_0': q_temp[group['user_ids']==0],\n",
    "                    'q_user_1': q_temp[group['user_ids']==1],\n",
    "                    'q_max_user_0': q_max[group['user_ids']==0],\n",
    "                    'q_max_user_1': q_max[group['user_ids']==1],\n",
    "                    'q_min_user_0': q_min[group['user_ids']==0],\n",
    "                    'q_min_user_1': q_min[group['user_ids']==1]}\n",
    "\n",
    "    # futures = []\n",
    "    # with concurrent.futures.ThreadPoolExecutor(max_workers=24) as executor:\n",
    "    #     for d in tqdm.tqdm(results):\n",
    "    #         future = executor.submit(func1, d)\n",
    "    #         futures.append(future)\n",
    "\n",
    "    results1 = []\n",
    "    for i, d in enumerate(tqdm.tqdm(results)):\n",
    "        results1.append(func1(d))\n",
    "\n",
    "        if i % 100000 == 0:\n",
    "            with open('../data/q_val_data_' + post + '.pkl', 'wb') as f:\n",
    "                pickle.dump([results, results1], f)\n",
    "\n",
    "    # for future in tqdm.tqdm(futures):\n",
    "    #     results1.append(future.result())\n",
    "\n",
    "    with open('../data/q_val_data_' + post + '.pkl', 'wb') as f:\n",
    "        pickle.dump([results, results1], f)\n",
    "\n",
    "else:\n",
    "\n",
    "    with open('../data/q_val_data_' + post + '.pkl', 'rb') as f:\n",
    "        results, results1 = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f44b79a3083351f69b3e1c3080f8b68c85400f1e3f9274646c7d9776fff2bccb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
